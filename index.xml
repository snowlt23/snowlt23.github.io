<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>snowlt23&#39;s website</title>
    <link>https://snowlt23.github.io/</link>
    <description>Recent content on snowlt23&#39;s website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Sun, 24 Dec 2017 05:20:09 +0900</lastBuildDate>
    
	<atom:link href="https://snowlt23.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Supercon2017参加記</title>
      <link>https://snowlt23.github.io/post/supercon2017/</link>
      <pubDate>Sun, 24 Dec 2017 05:20:09 +0900</pubDate>
      
      <guid>https://snowlt23.github.io/post/supercon2017/</guid>
      <description>この記事は N高等学校 Advent Calendar 2017 24日目のポエムです。
今更ですが今年の8月頃に開催されたSupercomputing Contest 2017(SuperCon)に参加した記録でも書こうと思います。
本当はFloriという自作言語の記事を書きたかったのですが処理系の実装が目標の段階まで到達できなかったので代わりにこちらを。
SuperConとは http://www.gsic.titech.ac.jp/supercon/main/attwiki/index.php
東京工業大学と大阪大学が主催するスーパーコンピューターを使っていい感じに問題を解くコンテストです。５日間(実質4日)かけて解くのでいわゆるマラソン？
事の発端 唐突にSuperCon出ない？とプロたちから誘われる。この時点では競技プログラミング自体は全くの門外漢だったのでどうしようかと戸惑いながらも面白そうなので出てみることにした。ちなみに後でなぜ誘ったのか聞いたらN高等学校学内Slackの#programmingチャンネル見てたら強そうだからという雑な理由だった。
予選 SuperConの予選はクセ無し種合成問題というものだった。競技プログラミングの門外漢でアルゴリズムに弱い僕はなんか適当な全探索みたいなのを書いて終わった気がする。
なおチームメイトのプロがビームサーチとか使ってめっちゃいい感じのコードを生成してくれたことにより予選を突破できた。:pray:
本戦前 地方勢なので東京まで飛行機で行った。なお東京自体はそこそこ慣れてたので特に問題はなかった。
前日に学校のプログラミング勢+講師で競プロ合宿をした。なお僕は飛行機の関係上途中参加。
本戦の前日の深夜に大阪大学関係で検索したらなんかめっちゃいい感じのSX-ACEの資料が出てきたので慌てて重要そうなところをメモる(SX-ACEはSuperCon2017で使うスパコン)
本戦 (ここからがメイン) 本戦問題 本戦の問題は音楽データの圧縮をする問題だった。圧縮といっても色々な圧縮アルゴリズムで片っ端から小さくしろという問題ではなく、PCMデータを音の定数分の上下で表す非可逆圧縮をするという問題。今回求めなくてはならないのはより元の音源を再現できる定数と上下の配列。
で、その圧縮の際に利用するのが大阪大学に導入されているスーパーコンピュータであるSX-ACE。SX-ACEはベクトル型計算機というもので、ざっくりいうと配列に対して同じような処理を複数回適用する際にベクトル化していい感じに高速に計算できる。今回のコンテストはスパコンがメインのコンテストなので、これを有効活用しないといけない。
本戦開始 1日目 とりあえず３人でそれぞれ別な感じの方針でいくことに。この時僕は何を書いたかあまり覚えていない（なんかその時点ではそこそこスコア出てたけどすぐにプロに抜かれて完全に忘却の彼方へいってしまった）
2日目 プロが三分探索とかを使ってめっちゃいい感じのスコアを出す。ここからこれを改良していく方針になる。 これを改良していって特にすることがなくなっていた。わりと３人共暇（２人はもとから暇）になってくる。
この時点でプロがDP解を思いついたらしいが実装がやばいらしく一旦保留。
3日目 プロが気合でDP解の実装をする。なんかめっちゃやばいスコアが出て３人で笑ってた。しかしこの時点で大きな問題があって、DPでも計算量がめちゃめちゃ重くてすごい小さな音楽データでないと時間内に計算しおわらない。
そこで僕はプロが実装したDP解の高速化に取り掛かった。ようやくまともな仕事をすることになる。 ここでさらに問題発生。プロが実装したDPにバグがあることが発覚。プロは気合でデバッグを開始。
高速化の話 (申し訳程度の技術情報) そして僕の高速化はめちゃめちゃ上手く行った。なんかぽんぽんと速度が見違えるように速くなってそこそこ小さめの問題なら解ける程度の速度まで持っていけた。普段はC,Rust,Nimみたいなシステムプログラミング言語とかばかり触っているおかげだろうか。
ちなみにここでした最適化は、主にメモリレイアウトへのアクセスの調整とベクトル化の２つ。
メモリは基本的にCPUに比べると遅いハードなのでメモリからCPUのキャッシュへ上手く載せることが重要になる。で、メモリからキャッシュに載せる際にメモリからは必要なデータだけでなくその周辺のデータもキャッシュへ読み込まれる。なので、連続でアクセスするデータがメモリとして連続しているとメモリアクセスが超高速化されてハッピーということだ。
具体的には、
int arr[100][1000];  という配列が合った時に、
for (int j=0; j&amp;lt;1000; j++) { for (int i=0; i&amp;lt;100; i++) { process(arr[i][j]); } }  とするよりも、
for (int i=0; i&amp;lt;100; i++) { for (int j=0; j&amp;lt;1000; j++) { process(arr[i][j]); } }  としたほうが高速になるという具合だ。こうすることにより連続したメモリ領域へのアクセスとなり、メモリアクセスの際に上手くキャッシュに載りかなり高速化される。</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://snowlt23.github.io/about/</link>
      <pubDate>Sun, 24 Dec 2017 05:03:42 +0900</pubDate>
      
      <guid>https://snowlt23.github.io/about/</guid>
      <description> snowlt23 (Shunsuke Ogata)  プログラマ N高等学校生徒 2016年度N予備校ドワンゴインターン生 Superconputing Contest 2017 4位  Skills  プログラミング言語  Nim C JavaScript  言語処理系 低レイヤー 最適化 WASM  Products  Twim (Twitter Image Downloader Chrome拡張(WASM)) nim-peheader (PEヘッダパーサ) wasm-bench-site (WASMベンチマークサイト)  Socials  Github: https://github.com/snowlt23 Twitter: https://twitter.com/snowlt23 Qiita: https://qiita.com/snowlt23  </description>
    </item>
    
  </channel>
</rss>